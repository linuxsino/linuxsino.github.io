<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Xin Liu – Publication</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="container">
    
<aside class="sidebar">
  <img src="images/xin_liu.jpg" alt="Xin Liu">
  <h1>Xin Liu</h1>
  <p>Associate Professor<br>CVPRL, LUT University</p>
  <nav>
    <a href="index.html">Home</a>
    <a href="publication.html">Publications</a>
    <a href="research.html">Research</a>
    <a href="team.html">Team</a>
    <a href="position.html">Position</a>
  </nav>
  <div class="updated">Last updated: July 5, 2025</div>
</aside>

    <main class="main">
      
<h2>Publications</h2>      
<ol reversed class="publication-list" start="63">
        <li>D. Li, B. Xing, <b>X. Liu</b>, B. Xia, B. Wen, and H. Kälviäinen. “DEEMO: De-identity Multimodal Emotion Recognition and Reasoning.” <i><b>ACM International Conference on Multimedia (ACMMM)</b></i>, 2025.</li>

<li>Z. Hu, K. Yuan, <b>X. Liu</b>, Z. Yu, Y. Zong, J. Shi, H. Yue, and J. Yang. “FEALLM: Advancing Facial Emotion Analysis in Multimodal Large Language Models with Emotional Synergy and Reasoning.” <i><b>ACM International Conference on Multimedia (ACMMM)</b></i>, 2025.</li>

<li>S. Chu, J. Shi, X. Cheng, H. Chen, <b>X. Liu</b>, and G. Zhao. “To Remember, To Adapt, To Preempt: A Stable Continual Test-Time Adaptation Framework for Remote Physiological Measurement in Dynamic Domain Shifts.” <i><b>ACM International Conference on Multimedia (ACMMM)</b></i>, 2025.</li>

        <li>J. Yang, X. Lin, Z. Yu, L. Zhang, <b>X. Liu</b>, H. Li, X. Yuan, and X. Cao. “DADM: Dual Alignment of Domain and Modality for Face Anti-spoofing.” <i><b>International Conference on Computer Vision (ICCV)</b></i>, 2025.</li>
        <li>Q. Ye, Z. Yu, R. Shao, Y. Cui, X. Kang, <b>X. Liu</b>, P. Torr, and X. Cao. “CAT+: Investigating and Enhancing Audio-visual Understanding in Large Language Models.” <i><b>IEEE Transactions on Pattern Analysis and Machine Intelligence</b></i>, 2025. [<a href="https://github.com/rikeilong/Bay-CAT" target="_blank" rel="noopener noreferrer">source code</a>]</li>
        <li>Y. Zhang, H. Lu, <b>X. Liu*</b>, Y. Chen, and K. Wu. “Advancing Generalizable Remote Physiological Measurement through the Integration of Explicit and Implicit Prior Knowledge.” <i><b>IEEE Transactions on Image Processing</b></i>, 2025. [<a href="https://github.com/keke-nice/Greip" target="_blank" rel="noopener noreferrer">source code</a>]</li>
        <li>R. Gao, <b>X. Liu*</b>, Z. Hu, B. Xing, B. Xia, Z. Yu, and H. Kälviäinen. “FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding.” <i><b>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</b></i>, 2025. [<a href="https://github.com/Moomin-Fin/Ano" target="_blank" rel="noopener noreferrer">project & source code</a>]</li>
        <li>Y. Zhang, H. Lu, Q. Hu, Y. Wang, K. Yuan, <b>X. Liu</b>, and K. Wu. “Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model.” <i><b>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</b></i>, 2025. [<a href="https://github.com/keke-nice/Period-LLM" target="_blank" rel="noopener noreferrer">source code</a>]</li>
        <li>B. Xing, K. Yuan, Z. Yu, <b>X. Liu*</b>, and H. Kälviäinen. “AU-TTT: Vision Test-Time Training model for Facial Action Unit Detection.” <i><b>IEEE International Conference on Multimedia & Expo (ICME)</b></i>, 2025.</li>
        <li>S. Chu, M. Xia, M. Yuan, <b>X. Liu</b>, T. Seppanen, G. Zhao, and J. Shi. “CodePhys: Robust Video-based Remote Physiological Measurement through Latent Codebook Querying.” <i><b>IEEE Journal of Biomedical and Health Informatics</b></i>, 2025.</li>
        <li>C. Hao, Z. Yu, <b>X. Liu*</b>, J. Xu, H. Yue, and J. Yang. “A Simple yet Effective Network based on Vision Transformer for Camouflaged Object and Salient Object Detection.” <i><b>IEEE Transactions on Image Processing</b></i>, 2025. [<a href="https://github.com/linuxsino/SENet" target="_blank" rel="noopener noreferrer">source code</a>]</li>
        <li>C. Cao, H. Yue, <b>X. Liu</b>, and J. Yang. “Zero-shot Video Restoration and Enhancement Using Pre-Trained Image Diffusion Model.” <i><b>AAAI Conference on Artificial Intelligence (AAAI)</b></i>, 2025. [<a href="https://github.com/cao-cong/ZVRD" target="_blank" rel="noopener noreferrer">source code</a>]</li>
        <li><b>X. Liu</b>, K. Yuan, X. Niu, J. Shi, Z. Yu, H. Yue, and J. Yang. “Multi-scale Promoted Self-adjusting Correlation Learning for Facial Action Unit Detection.” <i><b>IEEE Transactions on Affective Computing</b></i>, 2024. [<a href="https://github.com/linuxsino/Self-adjusting-AU" target="_blank" rel="noopener noreferrer">source code</a>]</li>
     <li><b>X. Liu</b>, C. Hao, Z. Yu, H. Yue, and J. Yang. “From Recognition to Prediction: Leveraging Sequence Reasoning for Action Anticipation.” <i><b>ACM Transactions on Multimedia Computing, Communications, and Applications</b></i>, 2024.</li>

  <li>C. Liu, <b>X. Liu*</b>, Z. Yu, Y. Hou, H. Yue, and J. Yang. “Adversarial Robustness in RGB-Skeleton Action Recognition: Leveraging Attention Modality Reweighter.” <i><b>IEEE International Joint Conference on Biometrics (IJCB)</b></i>, 2024.</li>

  <li>X. Ge, <b>X. Liu*</b>, Z. Yu, J. Shi, C. Qi, J. Li, and H. Kälviäinen. “DiffFAS: Face Anti-Spoofing via Generative Diffusion Models.” <i><b>European Conference on Computer Vision (ECCV)</b></i>, 2024. [<a href="https://github.com/murphytju/DiffFAS" target="_blank" rel="noopener noreferrer">source code</a>]</li>

  <li>K. Yuan, Z. Yu, <b>X. Liu*</b>, W. Xie, H. Yue, and J. Yang. “AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors.” <i><b>European Conference on Computer Vision (ECCV)</b></i>, 2024. [<a href="https://github.com/yuankaishen2001/AUFormer" target="_blank" rel="noopener noreferrer">source code</a>]</li>

  <li>D. Li, B. Xing, and <b>X. Liu*</b>. “Enhancing Micro Gesture Recognition for Emotion Understanding via Context-aware Visual-Text Contrastive Learning.” <i><b>IEEE Signal Processing Letters</b></i>, 2024. [<a href="https://github.com/linuxsino/Visual-Text-MG" target="_blank" rel="noopener noreferrer">source code</a>]</li>

  <li>Z. Yu, R. Cai, Y. Cui, <b>X. Liu</b>, Y. Hu, and A. Kot. “Rethinking Vision Transformer and Masked Autoencoder in Multimodal Face Anti-Spoofing.” <i><b>International Journal of Computer Vision (IJCV)</b></i>, 2024.</li>

  <li><b>X. Liu</b>, Y. Zhang, Z. Yu, H. Lu, H. Yue, and J. Yang. “rPPG-MAE: Self-supervised Pretraining with Masked Autoencoders for Remote Physiological Measurements.” <i><b>IEEE Transactions on Multimedia</b></i>, 2024. [<a href="https://github.com/linuxsino/rPPG-MAE" target="_blank" rel="noopener noreferrer">source code</a>]</li>
  <li>R. Gao, <b>X. Liu*</b>, J. Yang, and H. Yue. “Multi-Channel Fused Lasso for Motion Detection in Dynamic Video Scenarios.” <i><b>IEEE Transactions on Consumer Electronics</b></i>, 2024. [<a href="https://github.com/linuxsino/MCFL" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li>Y. Zhou, C. Li, J. Liang, T. Xu, <b>X. Liu</b>, and J. Xu. “4K-Resolution Photo Exposure Correction at 125 FPS with ~8K Parameters.” <i><b>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</b></i>, 2024. [<a href="https://github.com/Zhou-Yijie/MSLTNet" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li>H. Yue, Y. Cheng, <b>X. Liu</b>, and J. Yang. “Recaptured Raw Screen Image and Video Demoiréing via Channel and Spatial Modulations.” <i><b>The Thirty-Seventh Annual Conference on Neural Information Processing Systems (NeurIPS)</b></i>, 2023. [<a href="https://github.com/tju-chengyijia/vd_raw" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li>C. Cao, H. Yue, <b>X. Liu</b>, and J. Yang. “Unsupervised HDR Image and Video Tone Mapping via Contrastive Learning.” <i><b>IEEE Transactions on Circuits and Systems for Video Technology</b></i>, 2023. [<a href="https://github.com/cao-cong/UnCLTMO" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li>H. Chen, H. Shi, <b>X. Liu</b>, X. Li, and G. Zhao. “SMG: A Micro-Gesture Dataset Towards Spontaneous Body Gestures for Emotional Stress State Analysis.” <i><b>International Journal of Computer Vision (IJCV)</b></i>, 2023.</li>

<li>C. Le and <b>X. Liu</b>. “Spatio-temporal Attention Graph Convolutional Networks for Skeleton-based Action Recognition.” <i><b>Scandinavian Conference on Image Analysis (SCIA)</b></i>, 2023. [<a href="https://github.com/MCuongLe/STA-GCN" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li>Z. Wang, Z. Yu, X. Wang, J. Li, C. Zhao, <b>X. Liu</b>, and Z. Lei. “Consistency Regularization for Deep Face Anti-Spoofing.” <i><b>IEEE Transactions on Information Forensics and Security</b></i>, Vol. 18, pp. 1127-1140, 2023. [<a href="https://github.com/clks-wzz/EPCR" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li>W. Zhou, S. Wen, Y. Liu, L. Liu, <b>X. Liu</b>, L. Chen. “Forgetting Memristor Based STDP Learning Circuit for Neural Networks.” <i><b>Neural Networks</b></i>, Vol. 158, pp. 293-304, 2023.</li>

<li>Y. Liu, L. Chen, C. Li, <b>X. Liu</b>, W. Zhou, K. Li. “Long-Term and Short-Term Memory Networks Based On Forgetting Memristors.” <i><b>Soft Computing</b></i>, 2023.</li>

<li>C. Gong, L. Chen, and <b>X. Liu</b>. “Convolutional networks with short-term memory effects.” <i><b>Microprocessors and Microsystems</b></i>, Vol. 98, 2023.</li>

<li>J. Guo, J. Yang, H. Yue, <b>X. Liu</b>, and K. Li. “Unsupervised Domain-Invariant Feature Learning for Cloud Detection of Remote Sensing Images.” <i><b>IEEE Transactions on Geoscience and Remote Sensing</b></i>, Vol. 60, 2022.</li>

<li>H. Shi, W. Peng, H. Chen, <b>X. Liu</b>, and G. Zhao. “Multiscale 3D Shift Graph Convolution Network for Emotion Recognition from Human Actions.” <i><b>IEEE Intelligent Systems</b></i>, Vol. 37, Issue 4, pp. 103-110, 2022.</li>

<li>R. Gao, <b>X. Liu</b>, J. Yang, and H. Yue. “CdCLR: Clip-Driven Contrastive Learning for Skeleton-Based Action Recognition.” <i><b>IEEE International Conference on Visual Communications and Image Processing (VCIP)</b></i>, 2022. [<a href="https://github.com/Erich-G/CdCLR" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li><b>X. Liu</b> and G. Zhao. “3D Skeletal Gesture Recognition using Sparse Coding of Time-Warping Invariant Riemannian Trajectories.” <i><b>IEEE Transactions on Multimedia</b></i>, Vol. 23, pp. 1841–1854, 2021.</li>

<li>Z. Yu, B. Zhou, J. Wan, P. Wang, H. Chen, <b>X. Liu</b>, S. Li, and G. Zhao. “Searching Multi-Rate and Multi-Modal Temporal Enhanced Networks for Gesture Recognition.” <i><b>IEEE Transactions on Image Processing</b></i>, Vol. 30, pp. 5626 - 5640, 2021. <b>The second prize of IEEE Finland Jt. Chapter SP/CAS Best Paper Award.</b></li>

<li><b>X. Liu</b>, H. Shi, H. Chen, Z. Yu, X. Li, and G. Zhao. “iMiGUE: An Identity-free Video Dataset for Micro-Gesture Understanding and Emotion Analysis.” <i><b>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</b></i>, pp. 10631-10642, 2021. [<a href="https://github.com/linuxsino/iMiGUE" target="_blank" rel="noopener noreferrer">project page</a>]</li>

<li>H. Shi, W. Peng, <b>X. Liu</b>, and G. Zhao. “Graph Adversarial Learning for Noisy Skeleton-based Action Recognition.” <i><b>IS&T International Symposium on Electronic Imaging (EI)</b></i>, 2021.</li>

<li><b>X. Liu</b>, H. Shi, X. Hong, H. Chen, D. Tao, and G. Zhao. “3D Skeletal Gesture Recognition via Hidden States Exploration.” <i><b>IEEE Transactions on Image Processing</b></i>, vol. 29, pp. 4583–4597, 2020.</li>

<li>H. Chen, <b>X. Liu</b>, J. Shi, and G. Zhao. “Temporal hierarchical dictionary guided decoding for online gesture segmentation and recognition.” <i><b>IEEE Transactions on Image Processing</b></i>, vol. 29, pp. 9689–9702, 2020.</li>

<li>Y. Li, S. Lan, <b>X. Liu</b>, B. Lu, and L. Wang. “An efficient volume repairing method by using a modified Allen-Cahn equation.” <i><b>Pattern Recognition</b></i>, vol. 107, 107478, 2020.</li>

<li>X. Huang, S. Wang, <b>X. Liu</b>, G. Zhao, X. Feng, and M. Pietikäinen. “Discriminative spatiotemporal local binary pattern with improved revisited projection for spontaneous facial micro-expression recognition.” <i><b>IEEE Transactions on Affective Computing</b></i>, vol. 10, no. 1, pp. 32–47, 2019. <b>ESI highly cited paper</b></li>

<li>Y. Xu, X. Hong, F. Porikli, <b>X. Liu</b>, J. Chen, and G. Zhao. “Saliency Integration: An Arbitrator Mode.” <i><b>IEEE Transactions on Multimedia</b></i>, vol. 21, no. 1, pp. 98–113, 2019.</li>

<li><b>X. Liu</b>, H. Shi, X. Hong, H. Chen, D. Tao, and G. Zhao. “Hidden states exploration for 3D skeleton-based gesture recognition.” <i><b>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</b></i>, pp. 1846–1855, 2019.</li>

<li><b>X. Liu</b> and G. Zhao. “3D Skeletal Gesture Recognition via Sparse Coding of Time-Warping Invariant Riemannian Trajectories.” <i><b>International Conference on Multimedia Modeling (MMM)</b></i>, pp. 678–690, 2019.</li>

<li><b>X. Liu</b> and G. Zhao. “Background Subtraction Using Multi-Channel Fused Lasso.” <i><b>IS&T International Symposium on Electronic Imaging (EI)</b></i>, pp. 2691–2695, 2019.</li>

<li>H. Chen, <b>X. Liu</b>, X. Li, and G. Zhao. “Analyze Spontaneous Gestures for Emotional Stress State Recognition: A Micro-Gesture Dataset and Analysis with Deep Learning.” <i><b>IEEE International Conference on Automatic Face & Gesture Recognition (FG)</b></i>, 2019.</li>

<li><b>X. Liu</b>, J. Yao, X. Hong, C. Qi, and G. Zhao. “Background subtraction using spatio-temporal group sparsity recovery.” <i><b>IEEE Transactions on Circuits and Systems for Video Technology</b></i>, vol. 28, no. 8, pp. 1737–1751, 2018.</li>

<li>J. Shi, <b>X. Liu</b>, Y. Zong, C. Qi, and G. Zhao. “Hallucinating face image by regularization models in high resolution feature space.” <i><b>IEEE Transactions on Image Processing</b></i>, vol. 27, no. 6, pp. 2980–2995, 2018.</li>

<li>Z. Zha, <b>X. Liu</b>, and X. Zhang. “Compressed sensing image reconstruction via adaptive sparse nonlocal regularization.” <i><b>Visual Computer</b></i>, vol. 34, no. 1, pp. 117–137, 2018.</li>

        <li>S. Lan, <b>X. Liu</b>, L. Wang, and C. Cui. “A visually guided framework for lung segmentation and visualization in chest CT Images.” <i><b>Journal of Medical Imaging and Health Informatics</b></i>, vol. 8, pp. 485–493, 2018.</li>

<li>J. Liang, J. Guo, <b>X. Liu</b>, and S. Lao. “Fine-Grained Image Classification with Gaussian Mixture Layer.” <i><b>IEEE Access</b></i>, vol. 6, pp. 53356-53367, 2018.</li>

<li>Z. Zha, X. Zhang, Q. Wang, L. Tang, and <b>X. Liu</b>. “Group-based sparse representation for image compressive sensing reconstruction with non-convex regularization.” <i><b>Neurocomputing</b></i>, vol. 296, pp. 55-63, 2018.</li>

<li>Z. Zha, X. Zhang, Y. Wu, Q. Wang, <b>X. Liu</b>, L. Tang, and X. Yuan. “Non-Convex Weighted Lp Nuclear Norm based ADMM Framework for Image Restoration.” <i><b>Neurocomputing</b></i>, vol. 311, pp. 209–224, 2018.</li>

<li>Y. Xu, X. Hong, <b>X. Liu</b>, and G. Zhao. “Saliency detection via bi-directional propagation.” <i><b>Journal of Visual Communication and Image Representation</b></i>, Vol. 53, pp. 113-121, 2018.</li>

<li>H. Chen, <b>X. Liu</b>, and G. Zhao. “Temporal Hierarchical Dictionary with HMM for Fast Gesture Recognition.” <i><b>International Conference on Pattern Recognition (ICPR)</b></i>, 2018.</li>

<li>H. Shi, <b>X. Liu</b>, X. Hong, and G. Zhao. “Bidirectional Long Short-Term Memory Variational Autoencoder.” <i><b>British Machine Vision Conference (BMVC)</b></i>, 2018. Spotlight.</li>

<li>Z. Zha, X. Zhang, L. Tang, and <b>X. Liu</b>. “Group sparsity residual constraint for image denoising with external nonlocal self-similarity prior.” <i><b>Neurocomputing</b></i>, Vol. 275, pp. 2294-2306, 2018.</li>

<li>Z. Zha, <b>X. Liu</b>, Z. Zhou, X. Huang, J. Shi, and X. Zhang. “Image denoising via group sparsity residual constraint.” <i><b>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</b></i>, 2017, pp. 1787–1791. Oral paper.</li>

<li>Z. Zha, <b>X. Liu</b>, X. Huang, and X. Zhang. “Analyzing the group sparsity based on the rank minimization methods.” <i><b>IEEE International Conference on Multimedia and Expo (ICME)</b></i>, 2017, pp. 883–888. <b>Best Paper Award</b>.</li>

<li><b>X. Liu</b>, G. Zhao, J. Yao, and C. Qi. “Background subtraction based on low-rank and structured sparse decomposition.” <i><b>IEEE Transactions on Image Processing</b></i>, vol. 24, no. 8, pp. 2502–2514, 2015. <b>ESI highly cited paper.</b> [<a href="https://github.com/linuxsino/LSD" target="_blank" rel="noopener noreferrer">source code</a>]</li>

<li>J. Shi, <b>X. Liu</b>, and C. Qi. “Global consistency, local sparsity and pixel correlation: A unified framework for face hallucination.” <i><b>Pattern Recognition</b></i>, vol. 47, no. 11, pp. 3520–3534, 2014.</li>

<li>J. Yao, <b>X. Liu</b>, and C. Qi. “Foreground detection using low rank and structured sparsity.” in <i><b>IEEE International Conference on Multimedia and Expo (ICME)</b></i>, 2014, pp. 1–6.</li>

<li><b>X. Liu</b> and C. Qi. “Future-data driven modeling of complex backgrounds using mixture of Gaussians.” <i><b>Neurocomputing</b></i>, vol. 119, pp. 439–453, 2013.</li>

      </ol>

    </main>
  </div>
</body>
</html>
